{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lqfxeMfbKMOES6FW9hKVtly5izGPxKp3",
      "authorship_tag": "ABX9TyPpY6g3dUs1aVRP/z6MIkvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsoojo/MLprogramming/blob/main/1week/wisdm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNFtUS08Kxj-",
        "outputId": "09beae5d-f5c6-4d69-ccc7-50635e34588c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5289 - loss: 2.3029 - val_accuracy: 0.7001 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7381 - loss: 0.6982 - val_accuracy: 0.7203 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7886 - loss: 0.5519 - val_accuracy: 0.8215 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8305 - loss: 0.4565 - val_accuracy: 0.8629 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8548 - loss: 0.4042 - val_accuracy: 0.8114 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.3649 - val_accuracy: 0.8813 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.2862 - val_accuracy: 0.8859 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.2324 - val_accuracy: 0.8933 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9232 - loss: 0.2067 - val_accuracy: 0.9025 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.1872 - val_accuracy: 0.9034 - val_loss: nan\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9118 - loss: nan\n",
            "테스트 정확도: 0.9034\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/3-2/MLprogramming/WISDM_ar_v1.1_raw.txt\", header=None)\n",
        "df = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/3-2/MLprogramming/WISDM_ar_v1.1_raw.txt\",\n",
        "    header=None,\n",
        "    names=[\"user\", \"activity\", \"timestamp\", \"x\", \"y\", \"z\"],\n",
        "    sep=\",\",          # 콤마로 먼저 나눔\n",
        "    engine=\"python\",\n",
        "    on_bad_lines=\"skip\"   # 잘못된 줄은 건너뛰기\n",
        ")\n",
        "\n",
        "# 각 행 끝에 붙은 ; 제거\n",
        "df[\"z\"] = df[\"z\"].str.replace(\";\", \"\", regex=False).astype(float)\n",
        "\n",
        "df.columns = [\"user\", \"activity\", \"timestamp\", \"x\", \"y\", \"z\"]\n",
        "\n",
        "# 2. activity 라벨 인코딩\n",
        "le = LabelEncoder()\n",
        "df[\"label\"] = le.fit_transform(df[\"activity\"])\n",
        "\n",
        "# 3. 슬라이딩 윈도우 (예: 200 샘플 = 10초) #오버래핑 > 정확성향상\n",
        "window_size = 200\n",
        "X, y = [], []\n",
        "data = df[[\"x\", \"y\", \"z\"]].values\n",
        "labels = df[\"label\"].values\n",
        "\n",
        "for i in range(0, len(data) - window_size, window_size):\n",
        "    X.append(data[i:i+window_size])\n",
        "    y.append(labels[i+window_size-1])  # 마지막 라벨 사용\n",
        "\n",
        "X = np.array(X)\n",
        "y = to_categorical(np.array(y))\n",
        "\n",
        "###############################################\n",
        "# X, y = [], []\n",
        "# window_size = 200\n",
        "\n",
        "# for user_id, user_df in df.groupby(\"user\"):\n",
        "#     activities = user_df[\"label\"].values\n",
        "#     signals = user_df[[\"x\", \"y\", \"z\"]].values\n",
        "\n",
        "#     for i in range(0, len(signals) - window_size, window_size):\n",
        "#         X.append(signals[i:i+window_size])\n",
        "#         # 윈도우 안에서 가장 많이 나온 activity 라벨 사용\n",
        "#         y.append(np.bincount(activities[i:i+window_size]).argmax())\n",
        "\n",
        "# X = np.array(X)\n",
        "# y = to_categorical(np.array(y))\n",
        "\n",
        "# 4. train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. CNN 모델 정의\n",
        "model = Sequential([\n",
        "    Conv1D(64, 3, activation=\"relu\", input_shape=(window_size, 3)),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(128, 3, activation=\"relu\"),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(y.shape[1], activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# 6. 학습\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# 7. 평가\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"테스트 정확도: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMDAuCNTWEFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}